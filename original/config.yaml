API:
  LARGE_API_KEY: key-here
  LARGE_MODEL: meta-llama/Meta-Llama-3.1-70B-Instruct
  LARGE_BASE_URL: https://api.deepinfra.com/v1/openai
  LARGE_MODE: api
  SMALL_MODEL: meta-llama/Meta-Llama-3.1-8B-Instruct
  SMALL_BASE_URL: https://api.deepinfra.com/v1/openai
  SMALL_API_KEY: key-here
  SMALL_MODE: api
HUGGINGFACE:
  HUB_PATH: yourusername/your-path-here
  PRIVATE: False
  PUSH_TO_HUB: False
PATH: # TODO update all the other configs with the new base urls AND the new system prompt things
  DEFAULT_PROMPTS: ./prompts
  INPUT: ./input
  OUTPUT: ./output
  PROMPTS: ./prompts
PHASE:
  PHASE_INDEX: 3
  WORK_IN_PHASES: False
SKIP:
  ANSWER_RELEVANCY_CHECK: False
  REPAIR_QA_TUPLES: False
  FILTER_CHUNKS: False
  QUESTION_CHECK: False
  CONVERSATION_GENERATION: False
SYSTEM:
  CHUNK_SIZE: 1900
  COMPLETION_MODE: False
  CONCURRENCY_LIMIT: 50
  CONVERSATION_INSTRUCTIONS: For this conversation, you are generating a chat between
    a generalist, generic AI assistant, and a human.
  DOUBLE_CHECK_COUNTER: 1
  DO_NOT_USE_SYSTEM_PROMPTS: False
  FINAL_ASSISTANT_PROMPTS_NO_RAG: [
  'You are a helpful AI assistant.',
  'You are A VASTLY intelligent ARTIFICIAL INTELLIGENCE with DOMAIN-EXPERT KNOWLEDGE from a variety of fields.
  
  USE your knowledge to be helpful and truthfully answer questions about the world.',
  "u are ai asstant plz answr questions"] # a wide variety of system prompts helps the AI learn better. What, you expect your users to spell things right?
  FINAL_ASSISTANT_PROMPTS_RAG: [
  'You are a helpful AI assistant. Some knowledge:
  
  {data}',
  
  '{data}
  
  You are an AI domain expert. Answer questions',
  'You are an AI with vast knowledge. Here is some potentially-relevant context:
  
  {data}

  Answer questions according to your knowledge.']
  STOP: True
  SUBSET_SIZE: 20
  USE_FILENAMES: False
  USE_SUBSET: True
SCRAPING:
  USE_GUTENBERG: False
  START_URL: "https://www.gutenberg.org/ebooks/bookshelf/57"
  MAX_BOOKS: 5
  MAX_FAILURES: 5